Env

llm_app -> (docling) or (gpu) on Prime
threads_service.py -> (cv) or (flask) on Prime
bridge -> (base)
