# Local tested successfully ollama serve with Chatbot
using only file server.py on env llm

# Next Step
### Additing csv QA for allowing corrrect specific answers 
